{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Sentence Embedding"
      ],
      "id": "700ef63c-b681-4dd2-b68c-6b30f364c540"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "torch.set_printoptions(edgeitems=10)"
      ],
      "id": "802c88c5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "text = \"today I solved some excellent algorithmic problems\""
      ],
      "id": "47c99074"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List All Tokens"
      ],
      "id": "51d4d76a-f25d-41bd-b3d4-3fe17140018e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 1: [CLS]\n",
            "Token 2: today\n",
            "Token 3: i\n",
            "Token 4: solved\n",
            "Token 5: some\n",
            "Token 6: excellent\n",
            "Token 7: algorithm\n",
            "Token 8: ##ic\n",
            "Token 9: problems\n",
            "Token 10: [SEP]"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "tokens = encoded.input_ids.tolist()[0]\n",
        "\n",
        "for i, token_id in enumerate(tokens):\n",
        "    decoded_token = tokenizer.decode(token_id)\n",
        "    print(f\"Token {i + 1}: {decoded_token}\")"
      ],
      "id": "b1dfc6f7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token IDs"
      ],
      "id": "63b9f8c9-c444-4ef2-8f86-d7976f7ae032"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2651,  1045, 13332,  2070,  6581,  9896,  2594,  3471,   102]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
          ]
        }
      ],
      "source": [
        "print(encoded['input_ids'])\n",
        "print(encoded['attention_mask'])"
      ],
      "id": "c246ef35"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Token Embeddings (Pre-Transformer)"
      ],
      "id": "a57c1a3a-71ba-425e-951f-6c48e4fe7fcc"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-1.7657e-01, -4.8236e-02,  3.7698e-02, -1.5718e-02,  6.3230e-03,\n",
            "          -3.1231e-02, -6.8169e-02, -6.7792e-03,  9.7239e-04,  1.3556e-01,\n",
            "           ...,  2.6754e-02, -9.8876e-02, -3.2883e-02, -1.1810e-01,\n",
            "          -2.7678e-02,  3.7858e-02,  1.6958e-01,  3.1008e-02,  1.1538e-01,\n",
            "          -2.0014e-01],\n",
            "         [ 1.8995e-01,  4.7778e-01, -6.4656e-01, -6.1997e-02,  4.4774e-01,\n",
            "          -2.2780e-01,  5.7647e-01,  1.0681e-01,  2.9041e-02,  1.0774e-01,\n",
            "           ...,  7.1426e-02,  2.2001e-02, -2.7119e-01,  4.6715e-01,\n",
            "           8.6744e-02, -3.0273e-01, -8.2688e-01,  4.9940e-02, -5.3608e-01,\n",
            "           4.4687e-01],\n",
            "         [-2.7146e-01, -5.1515e-01,  1.8001e-01,  1.7585e-01,  1.2130e-01,\n",
            "           6.6390e-01,  1.2929e+00,  4.1779e-01, -2.7987e-01,  3.0289e-01,\n",
            "           ...,  6.3417e-01,  6.7045e-01, -1.3659e-02,  5.6788e-01,\n",
            "           1.1616e-01, -8.0553e-02,  1.1190e+00, -5.5179e-01, -7.2330e-01,\n",
            "          -7.1802e-01],\n",
            "         [-6.0968e-01, -4.0770e-01, -3.0730e-01,  3.8708e-02, -2.9205e-01,\n",
            "          -4.1951e-02, -5.8146e-01,  9.1353e-01, -4.1309e-01, -1.6173e-01,\n",
            "           ...,  8.3081e-01, -1.4773e+00,  2.4436e-01, -7.9544e-02,\n",
            "           6.5479e-01, -1.4149e-01, -7.8195e-02, -8.4422e-02,  1.1799e-01,\n",
            "           1.8152e-01],\n",
            "         [-1.9096e-01, -3.6072e-01,  8.3481e-01,  9.3601e-02,  3.4255e-01,\n",
            "           1.0948e+00,  8.1275e-01, -4.6414e-01,  6.4786e-01, -2.2790e-01,\n",
            "           ...,  8.2637e-01, -5.2400e-01, -2.9220e-01, -6.8929e-01,\n",
            "           6.1511e-01, -2.9235e-01, -1.2255e+00,  4.5983e-01,  1.0182e-01,\n",
            "           1.4967e+00],\n",
            "         [-7.9104e-02,  8.3143e-01,  6.7941e-01,  6.1991e-01,  1.7785e-01,\n",
            "          -2.1396e-01, -9.1548e-01, -1.1262e+00,  2.3476e-02, -4.9030e-01,\n",
            "           ...,  3.9878e-01, -9.5930e-01, -2.1444e-01, -5.2507e-01,\n",
            "          -6.5482e-01, -2.9219e-01,  6.3567e-01,  1.1416e+00, -3.6889e-01,\n",
            "          -1.8787e-01],\n",
            "         [-6.0894e-01, -2.1787e-01,  6.1217e-02,  7.6465e-01, -3.9996e-01,\n",
            "           2.7005e-01, -5.2523e-01,  5.1379e-01,  2.2092e-01, -5.7316e-01,\n",
            "           ..., -2.6547e-01, -1.6166e-01, -2.1071e-01, -1.0361e+00,\n",
            "          -6.8081e-01,  7.2021e-01, -5.5970e-01,  1.3093e-01,  6.4896e-01,\n",
            "          -4.5385e-01],\n",
            "         [-7.2148e-01, -8.8430e-02,  2.6686e-01, -2.3929e-01, -1.5604e-01,\n",
            "          -3.9315e-01,  3.5304e-02, -4.8140e-01, -2.9455e-01, -1.9621e-01,\n",
            "           ..., -1.0177e-01,  5.9905e-01, -1.7337e-01,  1.5785e+00,\n",
            "          -1.2094e+00,  5.2311e-02, -2.5572e-01,  9.1654e-01, -4.8774e-01,\n",
            "          -6.9118e-01],\n",
            "         [-5.5590e-01, -1.9957e-01, -2.7372e-01,  4.9280e-01, -2.6312e-01,\n",
            "          -9.1470e-02,  3.3883e-01,  8.3022e-01, -5.7808e-02, -1.0963e+00,\n",
            "           ...,  8.8829e-01, -6.7421e-01, -8.2788e-01, -3.2660e-01,\n",
            "           1.2970e-01, -4.3259e-01, -2.9034e-01,  8.5349e-01, -2.9419e-01,\n",
            "           7.3596e-01],\n",
            "         [ 2.8259e-01,  1.1627e-01, -2.2899e-01,  8.1796e-02,  1.5522e-01,\n",
            "           1.9928e-01,  3.6918e-01, -1.5420e-03, -4.1289e-01, -2.2418e-01,\n",
            "           ...,  3.1814e-01,  6.4867e-01, -5.5823e-01,  3.8027e-01,\n",
            "          -2.6366e-01,  9.5441e-02, -1.1949e-01,  1.4183e-01, -4.9089e-02,\n",
            "          -9.9984e-02]]], grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "initial_embeddings = model.embeddings(encoded.input_ids)\n",
        "print(initial_embeddings.shape)\n",
        "print(initial_embeddings)"
      ],
      "id": "c2eab538"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing Embeddings with the Transformer"
      ],
      "id": "12970576-1c6d-4e13-9c95-65b596d5480d"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-1.6421e-01,  4.6603e-01,  4.8923e-02, -4.4581e-01, -1.0461e-01,\n",
            "          -4.0528e-01, -6.6394e-02, -2.6723e-01, -6.5087e-01, -4.0242e-02,\n",
            "           ...,  2.5490e-01, -1.5108e-01,  6.7190e-02, -3.3418e-01,\n",
            "           6.2685e-02,  1.6719e-01, -1.3060e-01,  2.3860e-01, -6.6323e-02,\n",
            "          -9.3048e-02],\n",
            "         [-5.2605e-01,  8.2774e-01,  7.2402e-01,  2.9397e-02,  4.2663e-01,\n",
            "          -5.6253e-01,  5.4013e-01,  3.5761e-01, -1.2588e+00, -1.1268e-01,\n",
            "           ..., -1.8822e-01, -3.2735e-01, -4.0970e-01, -6.9944e-01,\n",
            "          -2.5683e-01,  6.0083e-02, -3.8097e-02, -7.4507e-01, -1.1621e+00,\n",
            "           1.1199e+00],\n",
            "         [ 1.4730e-01,  2.5046e-01,  1.5792e-01, -7.9211e-01,  1.3057e-01,\n",
            "          -9.0308e-01,  1.2293e+00,  5.5824e-01, -9.2916e-01, -2.0250e-01,\n",
            "           ...,  7.0374e-01, -8.2109e-02,  1.9675e-01, -4.7967e-01,\n",
            "          -1.2882e-01,  1.6525e-01,  1.1664e+00, -2.0873e-01, -1.1386e+00,\n",
            "          -6.3680e-01],\n",
            "         [-4.8400e-01,  1.1230e+00,  6.6284e-01, -9.9388e-03, -5.3236e-01,\n",
            "          -4.7981e-01, -1.4304e-01, -3.7157e-01, -9.3108e-01,  2.1497e-01,\n",
            "           ...,  5.5806e-01, -7.4806e-01,  5.0244e-01,  7.9645e-02,\n",
            "          -1.4953e-02,  2.1733e-01, -2.5297e-01,  8.5898e-01,  3.0455e-01,\n",
            "          -1.1558e-01],\n",
            "         [-5.9849e-01,  2.5691e-01,  3.1275e-01, -2.1444e-01,  1.3558e-01,\n",
            "          -2.7388e-01,  4.8175e-01, -4.9943e-01, -4.2906e-01,  4.4109e-02,\n",
            "           ...,  4.1643e-01, -2.9577e-02,  4.4056e-02, -2.0095e-01,\n",
            "           2.4035e-01,  2.9411e-01,  2.3737e-02,  1.4311e-01, -1.1292e-01,\n",
            "           7.3899e-01],\n",
            "         [-4.3940e-01,  5.3120e-01,  4.1124e-01, -3.2481e-01, -4.7671e-01,\n",
            "          -1.4475e-02, -8.6200e-01,  1.3119e-01, -6.5566e-01,  3.6020e-01,\n",
            "           ...,  8.5152e-01, -1.3369e-01,  8.0342e-01, -9.0518e-01,\n",
            "          -1.5779e-01,  6.6710e-01,  8.3861e-01,  8.7153e-01, -3.5219e-01,\n",
            "           3.6777e-01],\n",
            "         [-9.6277e-01,  4.0366e-01,  5.0071e-02, -8.6648e-01, -3.1162e-01,\n",
            "          -1.8305e+00, -5.6561e-01, -6.1431e-01, -8.8984e-01, -9.3658e-02,\n",
            "           ...,  1.5724e-01, -5.6844e-01, -3.2014e-01, -4.9601e-01,\n",
            "           3.9750e-01, -2.3013e-01, -8.1257e-01, -2.7416e-01,  9.1096e-01,\n",
            "          -1.1934e+00],\n",
            "         [-5.9778e-01,  6.4889e-01, -2.7592e-01, -3.1454e-01,  4.4997e-02,\n",
            "          -4.5742e-01,  4.6801e-01, -4.3574e-01, -6.0422e-01,  1.6758e-01,\n",
            "           ...,  3.3344e-01,  2.8306e-01,  1.2489e-01, -5.5690e-01,\n",
            "           1.2017e-01,  3.9964e-01,  1.4688e-01,  2.1022e-01, -1.2167e-01,\n",
            "          -2.8873e-01],\n",
            "         [-8.4109e-01,  7.7502e-01,  2.1054e-01, -3.1131e-01, -8.9244e-01,\n",
            "          -1.9417e-01,  7.3135e-01,  1.8437e-01, -1.4688e+00,  2.3883e-01,\n",
            "           ...,  1.1335e+00,  3.9202e-03,  2.3200e-01, -4.4012e-01,\n",
            "           2.3846e-01,  1.7987e-01,  1.0655e-01,  1.0205e+00, -1.0439e-01,\n",
            "           5.4115e-01],\n",
            "         [-3.7635e-01,  5.1624e-01, -3.2550e-01, -7.7124e-01,  1.1540e-03,\n",
            "          -9.1239e-01,  3.1114e-01, -4.3608e-01, -1.1094e+00, -2.2377e-02,\n",
            "           ...,  2.1022e-01, -3.2188e-01,  9.7225e-02, -5.6657e-01,\n",
            "           2.8814e-01,  5.8716e-01,  3.5164e-01,  2.3741e-01, -5.4676e-02,\n",
            "          -1.9115e-01]]], grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "output = model(**encoded)\n",
        "print(output.last_hidden_state.shape)\n",
        "print(output.last_hidden_state)"
      ],
      "id": "a3189263"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Pooling\n",
        "\n",
        "Since the attention mask consists entirely of `1`s (no padding tokens),\n",
        "we can safely compute the simple mean over all token embeddings. If the\n",
        "attention mask contains `0`s (indicating padding), a weighted mean that\n",
        "accounts for valid tokens is required instead."
      ],
      "id": "6f2c6ef9-d4be-489f-8c5c-d3180582357d"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert torch.all(encoded['attention_mask'] == 1)"
      ],
      "id": "f0a12ea9"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4843,  0.5799,  0.1977, -0.4021, -0.1579, -0.6034,  0.2125, -0.1393,\n",
            "         -0.8927,  0.0554,  ...,  0.4431, -0.2075,  0.1338, -0.4599,  0.0789,\n",
            "          0.2508,  0.1400,  0.2352, -0.1897,  0.0249]],\n",
            "       grad_fn=<MeanBackward1>)"
          ]
        }
      ],
      "source": [
        "pooling = output.last_hidden_state.mean(dim=1)\n",
        "print(pooling)"
      ],
      "id": "57d9578f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}