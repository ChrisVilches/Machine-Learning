{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Sentence Embedding"
      ],
      "id": "371d2be4-4c1b-4ce3-96d4-ccbb6ab5dd08"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "torch.set_printoptions(sci_mode=False)\n",
        "torch.set_printoptions(threshold=15)"
      ],
      "id": "2d3dc905"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "text = \"today I solved some excellent algorithmic problems\""
      ],
      "id": "beca7efa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List All Tokens"
      ],
      "id": "d65b4118-f3e4-43d2-a355-29c77119434f"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 1: [CLS]\n",
            "Token 2: today\n",
            "Token 3: i\n",
            "Token 4: solved\n",
            "Token 5: some\n",
            "Token 6: excellent\n",
            "Token 7: algorithm\n",
            "Token 8: ##ic\n",
            "Token 9: problems\n",
            "Token 10: [SEP]"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "tokens = encoded.input_ids.tolist()[0]\n",
        "\n",
        "for i, token_id in enumerate(tokens):\n",
        "    decoded_token = tokenizer.decode(token_id)\n",
        "    print(f\"Token {i + 1}: {decoded_token}\")"
      ],
      "id": "a5b3d530"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token IDs"
      ],
      "id": "dd461d9d-7498-4cfe-97df-0a0050631877"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2651,  1045, 13332,  2070,  6581,  9896,  2594,  3471,   102]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
          ]
        }
      ],
      "source": [
        "print(encoded['input_ids'])\n",
        "print(encoded['attention_mask'])"
      ],
      "id": "3ed95f1c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Token Embeddings (Pre-Transformer)"
      ],
      "id": "e76a3a1d-9fbc-4e2c-af3a-c6895b139ae0"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-0.1766, -0.0482,  0.0377,  ...,  0.0310,  0.1154, -0.2001],\n",
            "         [ 0.1899,  0.4778, -0.6466,  ...,  0.0499, -0.5361,  0.4469],\n",
            "         [-0.2715, -0.5152,  0.1800,  ..., -0.5518, -0.7233, -0.7180],\n",
            "         ...,\n",
            "         [-0.7215, -0.0884,  0.2669,  ...,  0.9165, -0.4877, -0.6912],\n",
            "         [-0.5559, -0.1996, -0.2737,  ...,  0.8535, -0.2942,  0.7360],\n",
            "         [ 0.2826,  0.1163, -0.2290,  ...,  0.1418, -0.0491, -0.1000]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "initial_embeddings = model.embeddings(encoded.input_ids)\n",
        "print(initial_embeddings.shape)\n",
        "print(initial_embeddings)"
      ],
      "id": "4b621d59"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing Embeddings with the Transformer"
      ],
      "id": "2837d27c-05d2-421f-adc5-6d76b63ffaf2"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-0.1642,  0.4660,  0.0489,  ...,  0.2386, -0.0663, -0.0930],\n",
            "         [-0.5260,  0.8277,  0.7240,  ..., -0.7451, -1.1621,  1.1199],\n",
            "         [ 0.1473,  0.2505,  0.1579,  ..., -0.2087, -1.1386, -0.6368],\n",
            "         ...,\n",
            "         [-0.5978,  0.6489, -0.2759,  ...,  0.2102, -0.1217, -0.2887],\n",
            "         [-0.8411,  0.7750,  0.2105,  ...,  1.0205, -0.1044,  0.5411],\n",
            "         [-0.3763,  0.5162, -0.3255,  ...,  0.2374, -0.0547, -0.1911]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "output = model(**encoded)\n",
        "print(output.last_hidden_state.shape)\n",
        "print(output.last_hidden_state)"
      ],
      "id": "361ed1d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Pooling\n",
        "\n",
        "Since the attention mask consists entirely of `1`s (no padding tokens),\n",
        "we can safely compute the simple mean over all token embeddings. If the\n",
        "attention mask contains `0`s (indicating padding), a weighted mean that\n",
        "accounts for valid tokens is required instead."
      ],
      "id": "f96165ff-4fd4-4fc8-8950-08fa759c5035"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert torch.all(encoded['attention_mask'] == 1)"
      ],
      "id": "8e144e36"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4843,  0.5799,  0.1977,  ...,  0.2352, -0.1897,  0.0249]],\n",
            "       grad_fn=<MeanBackward1>)"
          ]
        }
      ],
      "source": [
        "pooling = output.last_hidden_state.mean(dim=1)\n",
        "print(pooling)"
      ],
      "id": "fb172209"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}