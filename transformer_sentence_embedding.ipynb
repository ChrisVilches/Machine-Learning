{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Sentence Embedding"
      ],
      "id": "2ca58ae7-3887-4e03-8443-2e3efd956bc5"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "torch.set_printoptions(sci_mode=False, edgeitems=5)"
      ],
      "id": "13a07531"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "text = \"today I solved some excellent algorithmic problems\""
      ],
      "id": "e1907b04"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List All Tokens"
      ],
      "id": "edd333ab-4450-402c-9bc9-e55501ecf46f"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 1: [CLS]\n",
            "Token 2: today\n",
            "Token 3: i\n",
            "Token 4: solved\n",
            "Token 5: some\n",
            "Token 6: excellent\n",
            "Token 7: algorithm\n",
            "Token 8: ##ic\n",
            "Token 9: problems\n",
            "Token 10: [SEP]"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "tokens = encoded.input_ids.tolist()[0]\n",
        "\n",
        "for i, token_id in enumerate(tokens):\n",
        "    decoded_token = tokenizer.decode(token_id)\n",
        "    print(f\"Token {i + 1}: {decoded_token}\")"
      ],
      "id": "3dc2f8f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token IDs"
      ],
      "id": "631fbda7-b0ca-4585-9dde-11c2a2659e4e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2651,  1045, 13332,  2070,  6581,  9896,  2594,  3471,   102]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
          ]
        }
      ],
      "source": [
        "print(encoded['input_ids'])\n",
        "print(encoded['attention_mask'])"
      ],
      "id": "b92ebd80"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Token Embeddings (Pre-Transformer)"
      ],
      "id": "5e215ef7-97e8-4659-95d4-39b7b6e9df45"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-0.1766, -0.0482,  0.0377, -0.0157,  0.0063,  ...,  0.0379,  0.1696,  0.0310,  0.1154, -0.2001],\n",
            "         [ 0.1899,  0.4778, -0.6466, -0.0620,  0.4477,  ..., -0.3027, -0.8269,  0.0499, -0.5361,  0.4469],\n",
            "         [-0.2715, -0.5152,  0.1800,  0.1759,  0.1213,  ..., -0.0806,  1.1190, -0.5518, -0.7233, -0.7180],\n",
            "         [-0.6097, -0.4077, -0.3073,  0.0387, -0.2921,  ..., -0.1415, -0.0782, -0.0844,  0.1180,  0.1815],\n",
            "         [-0.1910, -0.3607,  0.8348,  0.0936,  0.3426,  ..., -0.2924, -1.2255,  0.4598,  0.1018,  1.4967],\n",
            "         [-0.0791,  0.8314,  0.6794,  0.6199,  0.1778,  ..., -0.2922,  0.6357,  1.1416, -0.3689, -0.1879],\n",
            "         [-0.6089, -0.2179,  0.0612,  0.7646, -0.4000,  ...,  0.7202, -0.5597,  0.1309,  0.6490, -0.4538],\n",
            "         [-0.7215, -0.0884,  0.2669, -0.2393, -0.1560,  ...,  0.0523, -0.2557,  0.9165, -0.4877, -0.6912],\n",
            "         [-0.5559, -0.1996, -0.2737,  0.4928, -0.2631,  ..., -0.4326, -0.2903,  0.8535, -0.2942,  0.7360],\n",
            "         [ 0.2826,  0.1163, -0.2290,  0.0818,  0.1552,  ...,  0.0954, -0.1195,  0.1418, -0.0491, -0.1000]]], grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "initial_embeddings = model.embeddings(encoded.input_ids)\n",
        "print(initial_embeddings.shape)\n",
        "print(initial_embeddings)"
      ],
      "id": "4b653510"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Processing Embeddings with the Transformer"
      ],
      "id": "be7ab54f-9bda-4398-9608-8ec4a97fd22f"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[    -0.1642,      0.4660,      0.0489,     -0.4458,     -0.1046,  ...,      0.1672,     -0.1306,      0.2386,     -0.0663,     -0.0930],\n",
            "         [    -0.5260,      0.8277,      0.7240,      0.0294,      0.4266,  ...,      0.0601,     -0.0381,     -0.7451,     -1.1621,      1.1199],\n",
            "         [     0.1473,      0.2505,      0.1579,     -0.7921,      0.1306,  ...,      0.1652,      1.1664,     -0.2087,     -1.1386,     -0.6368],\n",
            "         [    -0.4840,      1.1230,      0.6628,     -0.0099,     -0.5324,  ...,      0.2173,     -0.2530,      0.8590,      0.3046,     -0.1156],\n",
            "         [    -0.5985,      0.2569,      0.3128,     -0.2144,      0.1356,  ...,      0.2941,      0.0237,      0.1431,     -0.1129,      0.7390],\n",
            "         [    -0.4394,      0.5312,      0.4112,     -0.3248,     -0.4767,  ...,      0.6671,      0.8386,      0.8715,     -0.3522,      0.3678],\n",
            "         [    -0.9628,      0.4037,      0.0501,     -0.8665,     -0.3116,  ...,     -0.2301,     -0.8126,     -0.2742,      0.9110,     -1.1934],\n",
            "         [    -0.5978,      0.6489,     -0.2759,     -0.3145,      0.0450,  ...,      0.3996,      0.1469,      0.2102,     -0.1217,     -0.2887],\n",
            "         [    -0.8411,      0.7750,      0.2105,     -0.3113,     -0.8924,  ...,      0.1799,      0.1066,      1.0205,     -0.1044,      0.5411],\n",
            "         [    -0.3763,      0.5162,     -0.3255,     -0.7712,      0.0012,  ...,      0.5872,      0.3516,      0.2374,     -0.0547,     -0.1911]]], grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "output = model(**encoded)\n",
        "print(output.last_hidden_state.shape)\n",
        "print(output.last_hidden_state)"
      ],
      "id": "0db36be3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Pooling\n",
        "\n",
        "Since the attention mask consists entirely of `1`s (no padding tokens),\n",
        "we can safely compute the simple mean over all token embeddings. If the\n",
        "attention mask contains `0`s (indicating padding), a weighted mean that\n",
        "accounts for valid tokens is required instead."
      ],
      "id": "f7c76cd7-a84d-4f5d-815b-672485bc80bd"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert torch.all(encoded['attention_mask'] == 1)"
      ],
      "id": "62c12141"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 384])\n",
            "tensor([[-0.4843,  0.5799,  0.1977, -0.4021, -0.1579,  ...,  0.2508,  0.1400,  0.2352, -0.1897,  0.0249]], grad_fn=<MeanBackward1>)"
          ]
        }
      ],
      "source": [
        "pooling = output.last_hidden_state.mean(dim=1)\n",
        "print(pooling.shape)\n",
        "print(pooling)"
      ],
      "id": "5f42f1b2"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}