{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformer Sentence Embedding"
      ],
      "id": "cfec9d11-540d-4f81-b189-e5d1585f7c73"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, pipeline\n",
        "import torch"
      ],
      "id": "c636bdd6"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "text = \"today I solved some excellent algorithmic problems\""
      ],
      "id": "ede09dfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## List All Tokens"
      ],
      "id": "866f249b-aab5-46cc-83e4-60d858d2398f"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 1: [CLS]\n",
            "Token 2: today\n",
            "Token 3: i\n",
            "Token 4: solved\n",
            "Token 5: some\n",
            "Token 6: excellent\n",
            "Token 7: algorithm\n",
            "Token 8: ##ic\n",
            "Token 9: problems\n",
            "Token 10: [SEP]"
          ]
        }
      ],
      "source": [
        "encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
        "\n",
        "tokens = encoded.input_ids.tolist()[0]\n",
        "\n",
        "for i, token_id in enumerate(tokens):\n",
        "    decoded_token = tokenizer.decode(token_id)\n",
        "    print(f\"Token {i + 1}: {decoded_token}\")"
      ],
      "id": "a5c48b1d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token IDs"
      ],
      "id": "e7f2a376-e015-43e3-ab74-89e3f5a63419"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101,  2651,  1045, 13332,  2070,  6581,  9896,  2594,  3471,   102]])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
          ]
        }
      ],
      "source": [
        "print(encoded['input_ids'])\n",
        "print(encoded['attention_mask'])"
      ],
      "id": "ec6eaa3b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Executing the Model"
      ],
      "id": "161804a6-8cf5-4f1e-93ec-26c0f4e1e3f3"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 384])\n",
            "tensor([[[-0.1642,  0.4660,  0.0489,  ...,  0.2386, -0.0663, -0.0930],\n",
            "         [-0.5260,  0.8277,  0.7240,  ..., -0.7451, -1.1621,  1.1199],\n",
            "         [ 0.1473,  0.2505,  0.1579,  ..., -0.2087, -1.1386, -0.6368],\n",
            "         ...,\n",
            "         [-0.5978,  0.6489, -0.2759,  ...,  0.2102, -0.1217, -0.2887],\n",
            "         [-0.8411,  0.7750,  0.2105,  ...,  1.0205, -0.1044,  0.5411],\n",
            "         [-0.3763,  0.5162, -0.3255,  ...,  0.2374, -0.0547, -0.1911]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)"
          ]
        }
      ],
      "source": [
        "output = model(**encoded)\n",
        "print(output.last_hidden_state.shape)\n",
        "print(output.last_hidden_state)"
      ],
      "id": "78417587"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mean Pooling (Manually)\n",
        "\n",
        "Since the attention mask consists entirely of `1`s (no padding tokens),\n",
        "we can safely compute the simple mean over all token embeddings. If the\n",
        "attention mask contains `0`s (indicating padding), a weighted mean that\n",
        "accounts for valid tokens is required instead."
      ],
      "id": "dd713fd5-a9a0-4827-a364-da84d21f7af7"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert torch.all(encoded['attention_mask'] == 1)"
      ],
      "id": "a8e2d2b0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1642,  0.4660,  0.0489,  ...,  0.2386, -0.0663, -0.0930],\n",
            "        [-0.5260,  0.8277,  0.7240,  ..., -0.7451, -1.1621,  1.1199],\n",
            "        [ 0.1473,  0.2505,  0.1579,  ..., -0.2087, -1.1386, -0.6368],\n",
            "        ...,\n",
            "        [-0.5978,  0.6489, -0.2759,  ...,  0.2102, -0.1217, -0.2887],\n",
            "        [-0.8411,  0.7750,  0.2105,  ...,  1.0205, -0.1044,  0.5411],\n",
            "        [-0.3763,  0.5162, -0.3255,  ...,  0.2374, -0.0547, -0.1911]],\n",
            "       grad_fn=<MeanBackward1>)"
          ]
        }
      ],
      "source": [
        "manual_pooling = output.last_hidden_state.mean(dim=0)\n",
        "print(manual_pooling)"
      ],
      "id": "9f7aa1c8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculate Pooling Using Library"
      ],
      "id": "da665477-29f5-4938-88a6-1a9d828b9c8a"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.1642,  0.4660,  0.0489,  ...,  0.2386, -0.0663, -0.0930],\n",
            "         [-0.5260,  0.8277,  0.7240,  ..., -0.7451, -1.1621,  1.1199],\n",
            "         [ 0.1473,  0.2505,  0.1579,  ..., -0.2087, -1.1386, -0.6368],\n",
            "         ...,\n",
            "         [-0.5978,  0.6489, -0.2759,  ...,  0.2102, -0.1217, -0.2887],\n",
            "         [-0.8411,  0.7750,  0.2105,  ...,  1.0205, -0.1044,  0.5411],\n",
            "         [-0.3763,  0.5162, -0.3255,  ...,  0.2374, -0.0547, -0.1911]]])"
          ]
        }
      ],
      "source": [
        "extractor = pipeline(\"feature-extraction\", model=model_name)\n",
        "pooling = torch.tensor(extractor(text))\n",
        "print(pooling)"
      ],
      "id": "ca9de8a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare Both Values"
      ],
      "id": "ded14582-def5-4996-8119-b5c92ad89623"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "True"
            ]
          }
        }
      ],
      "source": [
        "torch.allclose(manual_pooling, pooling, rtol=1e-5, atol=1e-8)"
      ],
      "id": "6bd2004c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  }
}